{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XupZVOfxlvpA",
        "outputId": "61bc4299-63a0-4bc6-e99e-d0f5f2019f17"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "# Checking version of tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-aAMsCMkE6Z",
        "outputId": "3ddf1a9b-7c0e-4ff3-aa91-7503022a7806"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import  Dropout, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras import layers, Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTQ7DJT6LUVC"
      },
      "source": [
        "# code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PwotGyE15vJX"
      },
      "outputs": [],
      "source": [
        "# data = 'D:/pw23_sr/Master Dataset'\n",
        "data = 'D:/pw23_sr/Augmented Dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Tu-ysbaf7n"
      },
      "source": [
        "## preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "71bEJqtm5vPU"
      },
      "outputs": [],
      "source": [
        "# Creating a Data Generator Object\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Creating a Data Generator Object\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "batches = 128\n",
        "height = 128\n",
        "width = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Q6nifT502C",
        "outputId": "51df3236-5139-4fe5-9ba4-bbd3f3341d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 42399 images belonging to 673 classes.\n"
          ]
        }
      ],
      "source": [
        "train_set = train_datagen.flow_from_directory(\n",
        "    directory = data,\n",
        "    target_size = (height, width),\n",
        "    batch_size = batches,\n",
        "    class_mode ='categorical',\n",
        "    subset = 'training',\n",
        "    shuffle= True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train_set.image_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10095 images belonging to 673 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_set = train_datagen.flow_from_directory(\n",
        "    directory = data,\n",
        "    target_size = (height, width),\n",
        "    batch_size = batches,\n",
        "    class_mode ='categorical',\n",
        "    subset = 'validation',\n",
        "    shuffle= False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VpmkjpZ1VOYa"
      },
      "outputs": [],
      "source": [
        "base = DenseNet121(weights='imagenet', include_top=False, input_shape = (height, width ,3), classes = 673)\n",
        "\n",
        "for layer in base.layers[:-8]:\n",
        "    layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(base)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1024, activation ='relu'))\n",
        "model.add(Dense(512, activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(673, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w-aaPs-i51C-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 4, 4, 1024)        7037504   \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1024)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 1024)              4096      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 673)               345249    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8963297 (34.19 MB)\n",
            "Trainable params: 2088865 (7.97 MB)\n",
            "Non-trainable params: 6874432 (26.22 MB)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# from tensorflow.keras.optimizers import RMSProp\n",
        "from tensorflow.keras.optimizers.experimental import RMSprop\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "model.compile(optimizer= RMSprop(learning_rate= 0.001), loss = 'categorical_crossentropy', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=673, average='macro')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2lsUWgTO5vVi"
      },
      "outputs": [],
      "source": [
        "logdir = 'logs'\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "qJsq5C7L5rCL",
        "outputId": "8b79d4ed-4a36-4d9b-f29a-5ca3f680d68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "332/332 [==============================] - 895s 3s/step - loss: 4.5452 - accuracy: 0.2008 - precision: 0.8721 - recall: 0.0309 - f1_score: 0.1947 - val_loss: 4.1729 - val_accuracy: 0.2378 - val_precision: 0.8312 - val_recall: 0.0259 - val_f1_score: 0.2201\n",
            "Epoch 2/5\n",
            "332/332 [==============================] - 916s 3s/step - loss: 2.3877 - accuracy: 0.5237 - precision: 0.9111 - recall: 0.2054 - f1_score: 0.5193 - val_loss: 3.5224 - val_accuracy: 0.3135 - val_precision: 0.8273 - val_recall: 0.0992 - val_f1_score: 0.3070\n",
            "Epoch 3/5\n",
            "332/332 [==============================] - 940s 3s/step - loss: 1.6891 - accuracy: 0.6498 - precision: 0.9172 - recall: 0.3858 - f1_score: 0.6489 - val_loss: 3.4707 - val_accuracy: 0.3085 - val_precision: 0.6485 - val_recall: 0.1579 - val_f1_score: 0.3128\n",
            "Epoch 4/5\n",
            "332/332 [==============================] - 913s 3s/step - loss: 1.3878 - accuracy: 0.6997 - precision: 0.9183 - recall: 0.4889 - f1_score: 0.6995 - val_loss: 3.1977 - val_accuracy: 0.3594 - val_precision: 0.6969 - val_recall: 0.2014 - val_f1_score: 0.3572\n",
            "Epoch 5/5\n",
            "332/332 [==============================] - 934s 3s/step - loss: 1.2066 - accuracy: 0.7385 - precision: 0.9217 - recall: 0.5551 - f1_score: 0.7386 - val_loss: 3.2049 - val_accuracy: 0.3582 - val_precision: 0.6835 - val_recall: 0.2221 - val_f1_score: 0.3566\n"
          ]
        }
      ],
      "source": [
        "spe = len(train_set) \n",
        "vs = len(valid_set) \n",
        "\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs = 5, steps_per_epoch = spe, validation_steps = vs, callbacks = [tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./MyModel_tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./MyModel_tf\\assets\n"
          ]
        }
      ],
      "source": [
        "# saving the model in tensorflow format\n",
        "model.save('./MyModel_tf',save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loading the saved model\n",
        "loaded_model = tf.keras.models.load_model('./MyModel_tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "logdir = 'logs_retrain'\n",
        "tensorboard_callback_retrain = tf.keras.callbacks.TensorBoard(log_dir = logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "332/332 [==============================] - 1195s 4s/step - loss: 1.1539 - accuracy: 0.7538 - precision: 0.9224 - recall: 0.5735 - f1_score: 0.7540 - val_loss: 3.2954 - val_accuracy: 0.3582 - val_precision: 0.6622 - val_recall: 0.2263 - val_f1_score: 0.3612\n",
            "Epoch 2/5\n",
            "332/332 [==============================] - 1215s 4s/step - loss: 1.0203 - accuracy: 0.7766 - precision: 0.9240 - recall: 0.6247 - f1_score: 0.7769 - val_loss: 3.1936 - val_accuracy: 0.3804 - val_precision: 0.6660 - val_recall: 0.2514 - val_f1_score: 0.3775\n",
            "Epoch 3/5\n",
            "332/332 [==============================] - 1217s 4s/step - loss: 0.9468 - accuracy: 0.7907 - precision: 0.9244 - recall: 0.6528 - f1_score: 0.7910 - val_loss: 3.2295 - val_accuracy: 0.3810 - val_precision: 0.6584 - val_recall: 0.2694 - val_f1_score: 0.3801\n",
            "Epoch 4/5\n",
            "332/332 [==============================] - 1223s 4s/step - loss: 0.8888 - accuracy: 0.8027 - precision: 0.9259 - recall: 0.6779 - f1_score: 0.8030 - val_loss: 3.1710 - val_accuracy: 0.3980 - val_precision: 0.6673 - val_recall: 0.2784 - val_f1_score: 0.3939\n",
            "Epoch 5/5\n",
            "332/332 [==============================] - 1224s 4s/step - loss: 0.8507 - accuracy: 0.8120 - precision: 0.9280 - recall: 0.6911 - f1_score: 0.8123 - val_loss: 3.1676 - val_accuracy: 0.3948 - val_precision: 0.6580 - val_recall: 0.2747 - val_f1_score: 0.3898\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2208270fdc0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# retraining the model\n",
        "loaded_model.fit(train_set, validation_data=valid_set, epochs = 5, steps_per_epoch=len(train_set), validation_steps=len(valid_set), callbacks = [tensorboard_callback_retrain])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the model as HDF5\n",
        "model.save('densenet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the history object to a pickle file\n",
        "history_pickle_path = 'densenet.pkl'\n",
        "with open(history_pickle_path, 'wb') as file:\n",
        "    pickle.dump(history.history, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Load the training history from the pickle file\n",
        "# history_pickle_path = 'inception_40_72.pkl'\n",
        "\n",
        "# with open(history_pickle_path, 'rb') as file:\n",
        "#     history = pickle.load(file)\n",
        "\n",
        "# # Extract training and validation loss from the history\n",
        "# train_loss = history['loss']\n",
        "# val_loss = history['val_loss']\n",
        "\n",
        "# # Plot training and validation loss with specified colors\n",
        "# epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# plt.plot(epochs, train_loss, 'b-', label='Training Loss')  # Blue color for training loss\n",
        "# plt.plot(epochs, val_loss, 'orange', label='Validation Loss')  # Orange color for validation loss\n",
        "# plt.title('Training and Validation Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Load the training history from the pickle file\n",
        "# history_pickle_path = 'inception_40_72.pkl'\n",
        "\n",
        "# with open(history_pickle_path, 'rb') as file:\n",
        "#     history = pickle.load(file)\n",
        "\n",
        "# # Extract training and validation accuracy from the history\n",
        "# train_accuracy = history['accuracy']\n",
        "# val_accuracy = history['val_accuracy']\n",
        "\n",
        "# # Plot training and validation accuracy\n",
        "# epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# plt.plot(epochs, train_accuracy, 'b-', label='Training Accuracy')  # Blue color for training accuracy\n",
        "# plt.plot(epochs, val_accuracy, 'orange', label='Validation Accuracy')  # Orange color for validation accuracy\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mXtgv0mVib_"
      },
      "source": [
        "# Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NO0SJigx2dtL"
      },
      "outputs": [],
      "source": [
        "# test_set = test_datagen.flow_from_directory(\n",
        "#     target_size = (224, 224),\n",
        "#     batch_size = 32,\n",
        "#     rescale = 1./255,\n",
        "#     class_mode = 'categorical'\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MjNXtSqNVj0B"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "\n",
        "# master_dataset_dir = data\n",
        "# folder_name = 'A14a'\n",
        "\n",
        "# folder_path = os.path.join(master_dataset_dir, folder_name)\n",
        "\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     image_path = os.path.join(folder_path, filename)\n",
        "\n",
        "#     try:\n",
        "#         image = Image.open(image_path)\n",
        "#         plt.imshow(image)\n",
        "#         plt.title(\"File name: \" + filename)\n",
        "#         plt.show()\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error occurred while processing {filename}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lb1ndUgChfY1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# x = layers.Dense(256, activation = 'gelu')(x)\n",
        "# x = layers.Dropout(0.4)(x)\n",
        "# x = layers.Dense(128, activation = 'gelu')(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "# x = layers.Dense(64, activation = 'gelu')(x)\n",
        "# x = layers.Dropout(0.1)(x)\n",
        "\n",
        "# x = layers.Dense(num_classes,activation = 'softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_rgXW0391rZX"
      },
      "outputs": [],
      "source": [
        "# !pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-LVqqmnI1eY-"
      },
      "outputs": [],
      "source": [
        "# import splitfolders\n",
        "# input_folder= '/content/gdrive/MyDrive/college/capstone/Master Dataset'\n",
        "# splitfolders.ratio(input_folder, output= \"Dataset\",\n",
        "#                    seed=42, ratio= (.8,.2), group_prefix= None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RSWwu1631etF"
      },
      "outputs": [],
      "source": [
        "# !zip -r /content/Dataset.zip /content/Dataset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "byE11MrGaY6z"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
